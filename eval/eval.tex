\chapter{Evaluation}
\label{chap:eval}

In order to evaluate the quality and effectiveness of the tool created from the project, we plan 
to investigate the following categories:

\begin{enumerate}
  \item \textbf{Speed}, in terms of the median and average time needed to analyse a contract
  \item \textbf{Coverage}, in terms of the percentage of EVM bytecode for which the gas estimates can be derived
  \item \textbf{Precision}, in terms of the gas estimates calculated
  \item \textbf{User experience}, in terms of the features of the tool and how easy they are to use
\end{enumerate}

For items 1 and 2, we aim to evaluate our tool against a dataset of over 70,000 unique Ethereum smart
contracts \cite{smart_contract_sanctuary}, and collect statistics regarding run time and code coverage.
These will be compared with other existing tools such as GASTAP and VisualGas. The tools are not
open source, and therefore we are only able to compare with the published statistics, and are
unable to verify the results ourselves in a similar setting.

Then, for item 3, we aim to evaluate the gas bounds derived from our tool against the gas cost of real
transactions, using 100 real transactions from 100 contracts randomly chosen from the dataset.
Then, we can compare the precision of these gas bounds with those generated by the Solidity compiler.
We can also compare the precision in terms of overhead with GASTAP. These can only be evaluated at a transaction
level, since no other existing tool is able to calculate precise gas bounds at a line of code level.

Finally, for item 4, we aim to evaluate the features of our tool against other existing tools, such
as the Remix IDE and VisualGas. We also plan on gathering user feedback based on the following 
metrics:
\begin{enumerate}
  \item \textbf{Responsiveness}, or the total time wasted on waiting as a percentage of total time spent on performing a task
  \item \textbf{System Usability Scale}, which is a questionnaire of ten items for rating overall user experience
  \item \textbf{Error Occurence Rate}, which is the number of times an error occurs for each task performed
  \item \textbf{Average Time on Task}, for the first attempt as well as for repeat attempts
  \item \textbf{Hint rate}, which is the number of times a user has to ask for hints on how to perform a particular task
\end{enumerate}

We plan on testing the tool with real users to gather these metrics, by asking them to perform the
following tasks:
\begin{itemize}
  \item Import a Solidity project
  \item Generate the EVM code mappings for the Solidity code
  \item Generate the Yul code mappings for the Solidity code
  \item Generate a heatmap of gas costs for the Solidity code
\end{itemize}

To consider the project a success, we would ideally like to achieve a speed comparable or better
than existing gas analysis tools, a higher coverage than existing tools, and comparable or better
precision than existing tools. This is because most existing tools only evaluate gas costs at a
transaction level, and breaking it down into line of code level may incur some loss of precision.
We would also like to create a rich user experience that has a high usability score, and is therefore
simple to navigate but powerful to use.